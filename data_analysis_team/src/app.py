# app.py - Advanced Data Analysis Streamlit App

import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import tempfile
import shutil
from datetime import datetime
from pathlib import Path
import sys
import io
import base64

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from main import AdvancedDataAnalyzer, run_advanced_analysis
    from config import DATA_CONFIG, ANALYSIS_CONFIG, REPORT_CONFIG
except ImportError as e:
    st.error(f"Import Error: {e}")
    st.error("Please ensure all required modules are available in the same directory.")
    st.stop()

# Configure Streamlit page
st.set_page_config(
    page_title="üöÄ Advanced AI Data Analysis Platform",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2c3e50;
        margin: 1rem 0;
    }
    .config-section {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.25rem;
        padding: 0.75rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.25rem;
        padding: 0.75rem;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

def save_uploaded_file(uploaded_file):
    """Save uploaded file to temporary directory and return the path."""
    try:
        # Create a temporary directory 
        temp_dir = tempfile.mkdtemp()
        file_path = os.path.join(temp_dir, uploaded_file.name)
        
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        return file_path
    except Exception as e:
        st.error(f"Error saving uploaded file: {e}")
        return None

def validate_columns(df, selected_columns, column_type):
    """Validate that selected columns exist in the dataset."""
    invalid_columns = [col for col in selected_columns if col not in df.columns]
    if invalid_columns:
        st.error(f"Invalid {column_type} columns: {invalid_columns}")
        return False
    return True

def get_download_link(data, filename, file_label):
    """Generate a download link for data."""
    if isinstance(data, pd.DataFrame):
        csv = data.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{file_label}</a>'
    else:
        b64 = base64.b64encode(data.encode()).decode()
        href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">{file_label}</a>'
    return href

def save_config_to_file(config_dict, filename="updated_config.py"):
    """Save the configuration to a Python file."""
    try:
        config_content = f"""# Updated configuration generated by Streamlit app
# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

DATA_CONFIG = {repr(config_dict)}

ANALYSIS_CONFIG = {repr(ANALYSIS_CONFIG)}

REPORT_CONFIG = {repr(REPORT_CONFIG)}
"""
        
        with open(filename, 'w') as f:
            f.write(config_content)
        
        return config_content
    except Exception as e:
        st.error(f"Error saving config file: {e}")
        return None

def main():
    # Header
    st.markdown('<h1 class="main-header">üöÄ Advanced AI Data Analysis Platform</h1>', unsafe_allow_html=True)
    st.markdown("**Powered by OpenAI GPT-4 & CrewAI Multi-Agent Framework**")
    
    # Sidebar for navigation
    st.sidebar.title("üìä Navigation")
    app_mode = st.sidebar.selectbox(
        "Choose Analysis Mode",
        ["üè† Home", "üì§ Data Upload & Configuration", "üî¨ Analysis Results", "‚öôÔ∏è Settings"]
    )
    
    if app_mode == "üè† Home":
        show_home_page()
    elif app_mode == "üì§ Data Upload & Configuration":
        show_upload_and_config()
    elif app_mode == "üî¨ Analysis Results":
        show_analysis_results()
    elif app_mode == "‚öôÔ∏è Settings":
        show_settings()

def show_home_page():
    st.markdown('<h2 class="sub-header">Welcome to Advanced Data Analysis</h2>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>ü§ñ AI-Powered Analysis</h3>
            <p>8 specialized AI agents working together using OpenAI GPT-4</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>üîß Smart Data Cleaning</h3>
            <p>Advanced missing value treatment with intelligent strategies</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>üìà Comprehensive EDA</h3>
            <p>Statistical analysis, visualizations, and business insights</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("### üöÄ Features")
    st.markdown("""
    - **Smart Data Upload**: Automatic encoding detection and format support
    - **Interactive Configuration**: Easy setup for analysis parameters
    - **AI-Powered Insights**: OpenAI-driven data analysis and recommendations
    - **Advanced Cleaning**: Sophisticated missing value treatment strategies
    - **Multi-Agent Analysis**: 8 specialized agents for comprehensive analysis
    - **Professional Reports**: Detailed markdown reports with visualizations
    - **Export Capabilities**: Download cleaned data and analysis reports
    """)
    
    st.markdown("### üìã How to Use")
    st.markdown("""
    1. **Upload Data**: Go to 'Data Upload & Configuration' and upload your CSV file
    2. **Configure Analysis**: Select target column, categorical/numerical columns
    3. **Run Analysis**: Our AI agents will analyze your data comprehensively
    4. **View Results**: Explore insights, statistics, and visualizations
    5. **Download Reports**: Get cleaned data and detailed analysis reports
    """)

def show_upload_and_config():
    st.markdown('<h2 class="sub-header">üì§ Data Upload & Configuration</h2>', unsafe_allow_html=True)
    
    # File upload section
    st.markdown("### üìÅ Upload Your Dataset")
    uploaded_file = st.file_uploader(
        "Choose a CSV file",
        type=['csv'],
        help="Upload a CSV file for analysis. The system supports various encodings and formats."
    )
    
    if uploaded_file is not None:
        # Save uploaded file
        file_path = save_uploaded_file(uploaded_file)
        
        if file_path:
            # Load and display dataset 
            try:
                df = pd.read_csv(file_path)
                st.success(f"‚úÖ File uploaded successfully! Shape: {df.shape}")
                
                # Display dataset preview
                st.markdown("### üëÄ Dataset Preview")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**First 5 rows:**")
                    st.dataframe(df.head())
                
                with col2:
                    st.markdown("**Dataset Info:**")
                    buffer = io.StringIO()
                    df.info(buf=buffer)
                    info_str = buffer.getvalue()
                    st.text(info_str)
                
                # Configuration section
                st.markdown('<h3 class="sub-header">‚öôÔ∏è Analysis Configuration</h3>', unsafe_allow_html=True)
                
                # Create configuration form
                with st.form("config_form"):
                    st.markdown("### üéØ Target Configuration")
                    
                    # Target column selection
                    target_column = st.selectbox(
                        "Select Target Column",
                        [""] + list(df.columns),
                        help="Choose the column you want to predict or analyze as the main target"
                    )
                    
                    # Date column selection
                    date_column = st.selectbox(
                        "Select Date Column (Optional)",
                        [""] + list(df.columns),
                        help="Choose a date column for time-series analysis (optional)"
                    )
                    
                    st.markdown("### üìä Column Type Classification")
                    
                    # Auto-detect column types
                    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**Categorical Columns:**")
                        categorical_columns = st.multiselect(
                            "Select Categorical Columns",
                            df.columns.tolist(),
                            default=categorical_cols,
                            help="Choose columns that contain categories or text data"
                        )
                    
                    with col2:
                        st.markdown("**Numerical Columns:**")
                        numerical_columns = st.multiselect(
                            "Select Numerical Columns",
                            df.columns.tolist(),
                            default=numeric_cols,
                            help="Choose columns that contain numerical data for statistical analysis"
                        )
                    
                    # Analysis parameters
                    st.markdown("### üî¨ Analysis Parameters")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        workflow_type = st.selectbox(
                            "Analysis Type",
                            ["advanced", "standard", "quick"],
                            help="Choose the depth of analysis"
                        )
                    
                    with col2:
                        missing_threshold = st.slider(
                            "Missing Value Threshold (%)",
                            0.0, 50.0, 5.0,
                            help="Columns with missing values above this threshold will be flagged"
                        )
                    
                    with col3:
                        correlation_threshold = st.slider(
                            "Correlation Threshold",
                            0.0, 1.0, 0.7,
                            help="Threshold for identifying highly correlated features"
                        )
                    
                    # Submit button
                    submitted = st.form_submit_button("üöÄ Configure & Run Analysis", type="primary")
                    
                    if submitted:
                        # Validation
                        errors = []
                        
                        if not target_column:
                            errors.append("‚ùå Please select a target column")
                        
                        if target_column and target_column not in df.columns:
                            errors.append(f"‚ùå Target column '{target_column}' not found in dataset")
                        
                        if not validate_columns(df, categorical_columns, "categorical"):
                            errors.append("‚ùå Invalid categorical columns selected")
                        
                        if not validate_columns(df, numerical_columns, "numerical"):
                            errors.append("‚ùå Invalid numerical columns selected")
                        
                        # Check for column overlap
                        overlap = set(categorical_columns) & set(numerical_columns)
                        if overlap:
                            st.warning(f"‚ö†Ô∏è Columns appear in both categorical and numerical: {overlap}")
                        
                        if errors:
                            for error in errors:
                                st.error(error)
                        else:
                            # Create configuration dictionary
                            config_dict = {
                                "file_path": file_path,
                                "target_column": target_column,
                                "date_column": date_column,
                                "categorical_columns": categorical_columns,
                                "numerical_columns": numerical_columns,
                                "missing_value_threshold": missing_threshold / 100,
                                "correlation_threshold": correlation_threshold,
                                "workflow_type": workflow_type
                            }
                            
                            # Store configuration in session state
                            st.session_state.config = config_dict
                            st.session_state.dataframe = df
                            st.session_state.file_path = file_path
                            st.session_state.config_ready = True
                            
                            # Display configuration
                            st.markdown('<div class="success-box">', unsafe_allow_html=True)
                            st.success("‚úÖ Configuration completed successfully!")
                            st.json(config_dict)
                            st.markdown('</div>', unsafe_allow_html=True)
                
                # Outside the form
                if 'config_ready' in st.session_state and st.session_state.config_ready:
                    # Save configuration file
                    config_dict = st.session_state.config
                    config_content = save_config_to_file(config_dict)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if config_content:
                            st.download_button(
                                label="üì• Download Configuration File",
                                data=config_content,
                                file_name="updated_config.py",
                                mime="text/plain"
                            )
                    
                    with col2:
                        if st.button("üöÄ Start Analysis", type="primary"):
                            # Run analysis
                            st.markdown("### üîÑ Running Analysis...")
                            run_analysis_workflow(config_dict, st.session_state.file_path)
                            # Reset the config_ready flag
                            st.session_state.config_ready = False
                            
            except Exception as e:
                st.error(f"Error loading dataset: {e}")
                st.error("Please check if the file is a valid CSV format.")

def run_analysis_workflow(config_dict, file_path):
    """Run the advanced data analysis workflow."""
    try:
        with st.spinner("ü§ñ AI agents are analyzing your data... This may take a few minutes."):
            # Initialize progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Update progress
            status_text.text("üîÑ Initializing Advanced Data Analyzer...")
            progress_bar.progress(10)
            
            # Create analyzer instance
            analyzer = AdvancedDataAnalyzer()
            
            status_text.text("üìä Loading and profiling dataset...")
            progress_bar.progress(30)
            
            # Run analysis
            result = analyzer.run_analysis(
                file_path, 
                workflow_type=config_dict.get("workflow_type", "advanced")
            )
            
            progress_bar.progress(80)
            status_text.text("üìã Generating comprehensive reports...")
            
            if result['success']:
                progress_bar.progress(100)
                status_text.text("‚úÖ Analysis completed successfully!")
                
                # Store results in session state
                st.session_state.analysis_result = result
                
                # Display success message
                st.success("üéâ Analysis completed successfully!")
                
                # Show key metrics
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "Dataset Rows", 
                        f"{result['report']['cleaning_stats']['original_shape'][0]:,}"
                    )
                
                with col2:
                    st.metric(
                        "Columns", 
                        result['report']['cleaning_stats']['original_shape'][1]
                    )
                
                with col3:
                    st.metric(
                        "Missing Values Cleaned", 
                        result['report']['cleaning_stats']['missing_before']
                    )
                
                with col4:
                    missing_after = result['report']['cleaning_stats']['missing_after']
                    total_cells = (result['report']['cleaning_stats']['original_shape'][0] * 
                                 result['report']['cleaning_stats']['original_shape'][1])
                    quality_score = ((1 - missing_after / total_cells) * 100) if total_cells > 0 else 100
                    st.metric(
                        "Data Quality", 
                        f"{quality_score:.1f}%"
                    )
                
                # Missing value treatment summary
                if result.get('cleaning_log'):
                    st.markdown("### üîß Missing Value Treatment Summary")
                    cleaning_df = pd.DataFrame(result['cleaning_log'])
                    st.dataframe(cleaning_df)
                
                # Download buttons
                st.markdown("### üì• Download Results")
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'cleaned_data' in result:
                        csv = result['cleaned_data'].to_csv(index=False)
                        st.download_button(
                            label="üìä Download Cleaned Dataset",
                            data=csv,
                            file_name=f"cleaned_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                
                with col2:
                    # Read the report file 
                    report_file = result['report'].get('report_file')
                    if report_file and os.path.exists(report_file):
                        with open(report_file, 'r', encoding='utf-8') as f:
                            report_content = f.read()
                        
                        st.download_button(
                            label="üìã Download Analysis Report",
                            data=report_content,
                            file_name=f"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
                
                st.info("üí° Go to 'Analysis Results' tab to view detailed findings and visualizations.")
                
            else:
                progress_bar.progress(100)
                status_text.text("‚ùå Analysis failed")
                st.error(f"Analysis failed: {result.get('error', 'Unknown error')}")
                
                # Display troubleshooting info
                st.markdown("### üîß Troubleshooting")
                st.markdown("""
                **Common issues:**
                - Check if your OpenAI API key is properly configured
                - Ensure the dataset is in valid CSV format
                - Verify that selected columns exist in the dataset
                - Check internet connection for AI model access
                """)
                
    except Exception as e:
        st.error(f"Critical error during analysis: {e}")
        st.exception(e)

def show_analysis_results():
    st.markdown('<h2 class="sub-header">üî¨ Analysis Results</h2>', unsafe_allow_html=True)
    
    if 'analysis_result' not in st.session_state:
        st.warning("‚ö†Ô∏è No analysis results found. Please upload data and run analysis first.")
        return
    
    result = st.session_state.analysis_result
    
    # Display analysis overview
    st.markdown("### üìä Analysis Overview")
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    cleaning_stats = result['report']['cleaning_stats']
    
    with col1:
        st.metric("Original Rows", f"{cleaning_stats['original_shape'][0]:,}")
    
    with col2:
        st.metric("Columns", cleaning_stats['original_shape'][1])
    
    with col3:
        st.metric("Missing Values Fixed", cleaning_stats['missing_before'])
    
    with col4:
        quality_score = ((1 - cleaning_stats['missing_after'] / 
                         (cleaning_stats['original_shape'][0] * cleaning_stats['original_shape'][1])) * 100)
        st.metric("Data Quality Score", f"{quality_score:.1f}%")
    
    # Analysis details
    if 'result' in result and hasattr(result['result'], 'raw'):
        st.markdown("### ü§ñ AI Analysis Report")
        
        # Display the raw analysis results
        with st.expander("üìã Detailed Analysis Results", expanded=True):
            st.markdown(result['result'].raw)
    
    # Cleaning log
    if 'cleaning_log' in result and result['cleaning_log']:
        st.markdown("### üîß Data Cleaning Details")
        
        cleaning_df = pd.DataFrame(result['cleaning_log'])
        
        # Create a more detailed view
        for idx, entry in enumerate(result['cleaning_log']):
            with st.expander(f"Column: {entry['column']} ({entry['data_type']})"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**Missing Percentage:** {entry['missing_percentage']}")
                    st.write(f"**Strategy Applied:** {entry['strategy']}")
                
                with col2:
                    st.write(f"**Reasoning:** {entry['reasoning']}")
    
    # Dataset preview
    if 'cleaned_data' in result:
        st.markdown("### üìä Cleaned Dataset Preview")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**First 10 rows:**")
            st.dataframe(result['cleaned_data'].head(10))
        
        with col2:
            st.markdown("**Dataset Statistics:**")
            st.dataframe(result['cleaned_data'].describe())
    
    # Configuration used
    if 'config' in st.session_state:
        st.markdown("### ‚öôÔ∏è Configuration Used")
        with st.expander("View Configuration Details"):
            st.json(st.session_state.config)

def show_settings():
    st.markdown('<h2 class="sub-header">‚öôÔ∏è Settings & Configuration</h2>', unsafe_allow_html=True)
    
    # API Configuration
    st.markdown("### üîë API Configuration")
    with st.expander("OpenAI API Settings", expanded=True):
        st.markdown("""
        **Current Status:** ‚úÖ OpenAI API Configured
        
        **Model:** GPT-4o-mini (Cost-optimized)
        
        **Features Enabled:**
        - AI-powered data insights
        - Advanced missing value strategies
        - Multi-agent analysis workflow
        - Intelligent data profiling
        """)
    
    # Analysis Configuration
    st.markdown("### üî¨ Analysis Configuration")
    with st.expander("Default Analysis Settings"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Outlier Detection Methods:**")
            st.write("- IQR (Interquartile Range)")
            st.write("- Z-Score")
            st.write("- Isolation Forest")
        
        with col2:
            st.write("**Default Thresholds:**")
            st.write(f"- Correlation: {ANALYSIS_CONFIG.get('correlation_threshold', 0.7)}")
            st.write(f"- Missing Values: {ANALYSIS_CONFIG.get('missing_value_threshold', 0.05)}")
            st.write(f"- Random State: {ANALYSIS_CONFIG.get('random_state', 42)}")
    
    # System Information
    st.markdown("### üíª System Information")
    with st.expander("Environment Details"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Python Packages:**")
            st.code("""
            streamlit
            pandas
            numpy
            crewai
            openai
            litellm
            matplotlib
            seaborn
            """)
        
        with col2:
            st.write("**Framework Version:**")
            st.write("- CrewAI: Multi-Agent Framework")
            st.write("- OpenAI: GPT-4o-mini")
            st.write("- Streamlit: Web Interface")
    
    # Reset options
    st.markdown("### üîÑ Reset Options")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üóëÔ∏è Clear Session Data"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.success("Session data cleared!")
            st.rerun()
    
    with col2:
        if st.button("üìä Reset to Default Config"):
            st.info("Default configuration restored!")

if __name__ == "__main__":
    # Initialize session state
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True

    main()
